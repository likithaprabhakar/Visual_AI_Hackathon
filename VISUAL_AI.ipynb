{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install segmentation-models-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsHXSKlbhvkP",
        "outputId": "bf9b3b54-cfb7-4710-82b0-cbf6fac42f5a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting segmentation-models-pytorch\n",
            "  Downloading segmentation_models_pytorch-0.4.0-py3-none-any.whl.metadata (32 kB)\n",
            "Collecting efficientnet-pytorch>=0.6.1 (from segmentation-models-pytorch)\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (1.26.4)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (11.1.0)\n",
            "Collecting pretrainedmodels>=0.7.1 (from segmentation-models-pytorch)\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (1.17.0)\n",
            "Requirement already satisfied: timm>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (1.0.14)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (4.12.2)\n",
            "Collecting munch (from pretrainedmodels>=0.7.1->segmentation-models-pytorch)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm>=0.9->segmentation-models-pytorch) (0.5.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8->segmentation-models-pytorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8->segmentation-models-pytorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8->segmentation-models-pytorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8->segmentation-models-pytorch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8->segmentation-models-pytorch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8->segmentation-models-pytorch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8->segmentation-models-pytorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8->segmentation-models-pytorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8->segmentation-models-pytorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8->segmentation-models-pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8->segmentation-models-pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8->segmentation-models-pytorch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2024.12.14)\n",
            "Downloading segmentation_models_pytorch-0.4.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.3/121.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16424 sha256=543b00b1f72d350cfa697e44955df5ee6f1ffbdd64a5ca05aeac61ce4f073422\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/6f/9b/231a832f811ab6ebb1b32455b177ffc6b8b1cd8de19de70c09\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60944 sha256=08a50b6876de5fcedc2910986d45af3f6b7f41b336c62392e8ddad07f3f95c0b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/5b/96/fd94bc35962d7c6b699e8814db545155ac91d2b95785e1b035\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, munch, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, efficientnet-pytorch, pretrainedmodels, segmentation-models-pytorch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qir5KMDBhgy-",
        "outputId": "1679fa2c-f385-40d8-d6b5-693ee1b71f6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ],
      "source": [
        "%load_ext tensorboard\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "import sklearn\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from collections import defaultdict\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "from tqdm.auto import tqdm\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import copy\n",
        "import time\n",
        "\n",
        "import segmentation_models_pytorch\n",
        "\n",
        "import albumentations as A\n",
        "#from albumentations.pytorch import ToTensorV2\n",
        "from albumentations.pytorch.transforms import ToTensorV2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"/content/new/Train/Labeled/Flooded/image\", exist_ok=True)\n",
        "os.makedirs(\"/content/new/Train/Labeled/Non-Flooded/image\", exist_ok=True)\n",
        "os.makedirs(\"/content/new/Train/Labeled/Flooded/mask\", exist_ok=True)\n",
        "os.makedirs(\"/content/new/Train/Labeled/Non-Flooded/mask\", exist_ok=True)\n",
        "os.makedirs(\"/content/new/Train/Unlabeled/image\", exist_ok=True)\n",
        "os.makedirs(\"/content/new/Test/image\", exist_ok=True)"
      ],
      "metadata": {
        "id": "2Ir0qBG6hmco"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls /content/drive/MyDrive/FloodNet\\ Challenge\\ @\\ EARTHVISION\\ 2021\\ -\\ Track\\ 1/Train/Labeled\n",
        "\n",
        "!ls \"/content/drive/MyDrive/FloodNet Challenge @ EARTHVISION 2021 - Track 1/Train/Labeled\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKz_1tWNhqep",
        "outputId": "d27dea2d-1472-41ab-9e9e-72b917bbd3f1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flooded  Non-Flooded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!ls \"/content/new/Train/Labeled/Flooded\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rks7-LpniIFx",
        "outputId": "1a6587fc-419e-4e32-af6f-e63d28735d0d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image  mask\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RESIZE=(512,512)\n",
        "temp_root = \"/content/drive/MyDrive/FloodNet Challenge @ EARTHVISION 2021 - Track 1\"\n",
        "local_root = \"/content/new\"\n",
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Your resize and save function\n",
        "def resize_and_save(path, resize=(256, 256), samples=None):\n",
        "    # Assuming temp_root and local_root are defined elsewhere in your code\n",
        "    for img_name in tqdm(os.listdir(os.path.join(temp_root, path))[:samples]):\n",
        "        img_path = os.path.join(temp_root, path, img_name)\n",
        "\n",
        "        # Check if the file exists\n",
        "        if os.path.exists(img_path):\n",
        "            # Read the image\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "            # Check if image is successfully loaded\n",
        "            if img is not None:\n",
        "                # Resize the image\n",
        "                img_resized = cv2.resize(img, resize)\n",
        "\n",
        "                # Save the resized image\n",
        "                save_path = os.path.join(local_root, path, img_name)\n",
        "                cv2.imwrite(save_path, img_resized)\n",
        "            else:\n",
        "                print(f\"Error reading image: {img_path}\")\n",
        "        else:\n",
        "            print(f\"File does not exist: {img_path}\")\n"
      ],
      "metadata": {
        "id": "jbFaU9PJiLg0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resize_and_save(\"Train/Labeled/Flooded/image\")\n",
        "resize_and_save(\"Train/Labeled/Non-Flooded/image\")\n",
        "resize_and_save(\"Train/Labeled/Flooded/mask\")\n",
        "resize_and_save(\"Train/Labeled/Non-Flooded/mask\")\n",
        "resize_and_save(\"Train/Unlabeled/image\")\n",
        "resize_and_save(\"Test/image\")\n",
        "resize_and_save(\"Train/Unlabeled/image\", samples=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZUmhUN6ifFk",
        "outputId": "131f74a3-9e45-45cf-d2ca-5dba6048ae26"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 51/51 [00:11<00:00,  4.44it/s]\n",
            "100%|██████████| 347/347 [01:10<00:00,  4.94it/s]\n",
            "100%|██████████| 51/51 [00:06<00:00,  7.74it/s]\n",
            "100%|██████████| 347/347 [00:41<00:00,  8.29it/s]\n",
            "100%|██████████| 1047/1047 [11:28<00:00,  1.52it/s]\n",
            "100%|██████████| 448/448 [06:32<00:00,  1.14it/s]\n",
            "100%|██████████| 100/100 [00:23<00:00,  4.23it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flood_dir = \"Train/Labeled/Flooded\"\n",
        "non_flood_dir = \"Train/Labeled/Non-Flooded\"\n",
        "\n",
        "f_img_dir = os.path.join(local_root, flood_dir, \"image\")\n",
        "f_mask_dir = os.path.join(local_root, flood_dir, \"mask\")\n",
        "n_img_dir = os.path.join(local_root, non_flood_dir, \"image\")\n",
        "n_mask_dir = os.path.join(local_root, non_flood_dir, \"mask\")\n",
        "\n",
        "f_img = len(os.listdir(f_img_dir))\n",
        "f_mask = len(os.listdir(f_mask_dir))\n",
        "n_img = len(os.listdir(n_img_dir))\n",
        "n_mask = len(os.listdir(n_mask_dir))\n",
        "print(f\"Flooded images:      {f_img} Flooded masks:     {f_mask}\")\n",
        "print(f\"Non-Flooded images: {n_img} Non-Flooded masks: {n_mask}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IiGOALwiiWK",
        "outputId": "6d803a8e-8f14-4517-9ddd-75bd4a13aab8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flooded images:      51 Flooded masks:     51\n",
            "Non-Flooded images: 347 Non-Flooded masks: 347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLASSES={'Background':0,'Building-flooded':1,'Building-non-flooded':2,'Road-flooded':3,'Road-non-flooded':4,\n",
        "         'Water':5,'Tree':6,'Vehicle':7,'Pool':8,'Grass':9}\n",
        "IMG_DIM= 512"
      ],
      "metadata": {
        "id": "d41yJEOwmNmc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TENSORBOARD_DIR = \"/content/drive/MyDrive/runs_h/\"\n",
        "MODEL_DIR = \"/content/drive/MyDrive/models_h/\"\n",
        "UNLABELLED_SPLIT = 100\n",
        "\n",
        "os.makedirs(TENSORBOARD_DIR, exist_ok=True)\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "ENCODER_DEPTH=5\n",
        "DECODER_CHANNELS=256\n",
        "BATCH_SIZE= [8]\n",
        "EPOCHS= 100\n",
        "LR = [1e-3]\n",
        "ENCODER_NAME= 'efficientnet-b3'"
      ],
      "metadata": {
        "id": "3l_S4azcmT-0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dirs = \"\"\"\n",
        "flood_dir\n",
        "non_flood_dir\n",
        "\n",
        "f_img_dir\n",
        "f_mask_dir\n",
        "n_img_dir\n",
        "n_mask_dir\n",
        "\"\"\"\n",
        "x_f = [os.path.join(f_img_dir, file) for file in sorted(os.listdir(f_img_dir))]\n",
        "x_n = [os.path.join(n_img_dir, file) for file in sorted(os.listdir(n_img_dir))]\n",
        "\n",
        "x = x_f + x_n\n",
        "\n",
        "x_train, x_test = model_selection.train_test_split(x, test_size=0.3, shuffle=True)\n",
        "\n",
        "train_transform1 = A.Compose([\n",
        "        A.Resize(IMG_DIM, IMG_DIM),\n",
        "        A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.5),\n",
        "        # A.RGBShift(r_shift_limit=25, g_shift_limit=25, b_shift_limit=25, p=0.5),\n",
        "        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
        "    ])\n",
        "\n",
        "train_transform2=A.Compose([ToTensorV2()])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        ""
      ],
      "metadata": {
        "id": "3ITf3ixZmdge"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SegDataset:\n",
        "    def __init__(self, x_paths, trans1, trans2, img_dim, unlabelled=False):\n",
        "        self.x_paths = x_paths\n",
        "        self.unlabelled = unlabelled\n",
        "        if not self.unlabelled:\n",
        "            self.y_paths = [x.replace(\"image\", \"mask\").replace(\".jpg\", \"_lab.png\") for x in self.x_paths]\n",
        "        else:\n",
        "            self.y_paths = None\n",
        "        self.img_dim = img_dim\n",
        "        self.trans1 = trans1\n",
        "        self.trans2 = trans2\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_paths)\n",
        "\n",
        "    def get_newMask(self, mask, classes, dim=IMG_DIM):\n",
        "        if mask.ndim == 3:\n",
        "            mask = torch.as_tensor(mask[:,:,0], dtype=torch.int64)\n",
        "        elif mask.ndim == 2:\n",
        "            mask = torch.as_tensor(mask, dtype=torch.int64)\n",
        "        return torch.moveaxis(torch.nn.functional.one_hot(mask, num_classes=len(classes)), -1, 0)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Read and convert image\n",
        "        image = cv2.imread(self.x_paths[index])\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Preprocess the image (keep this consistent)\n",
        "        kernel = np.ones((2, 2), np.uint8)\n",
        "        image = cv2.bilateralFilter(image, 5, 75, 75)\n",
        "        image = cv2.erode(cv2.dilate(image, kernel, iterations=2), kernel, iterations=1)\n",
        "\n",
        "        # Read and preprocess mask (if not unlabelled)\n",
        "        if not self.unlabelled:\n",
        "            mask = cv2.imread(self.y_paths[index], cv2.IMREAD_GRAYSCALE)\n",
        "        else:\n",
        "            mask = np.random.rand(512, 512, 3)  # Dummy mask for unlabelled data\n",
        "\n",
        "        # Apply transformations to both image and mask\n",
        "        # Apply first transformation (resize and augment) to both image and mask\n",
        "        if self.trans1:\n",
        "            transformed1 = self.trans1(image=image, mask=mask)\n",
        "            image = transformed1[\"image\"]\n",
        "            mask = transformed1[\"mask\"]\n",
        "\n",
        "        # Apply second transformation (tensor conversion) to both image and mask\n",
        "        if self.trans2:\n",
        "            transformed2 = self.trans2(image=image, mask=mask)\n",
        "            image = transformed2[\"image\"]\n",
        "            mask = transformed2[\"mask\"]\n",
        "\n",
        "        return image, mask\n"
      ],
      "metadata": {
        "id": "CZ0cw_dbpHmL"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_loss(pred, target, smooth = 1e-5):\n",
        "    pred = pred.contiguous()\n",
        "    target = target.contiguous()\n",
        "\n",
        "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
        "\n",
        "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
        "\n",
        "    return loss.mean()"
      ],
      "metadata": {
        "id": "XFRxAsq1pSBF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss(pred, target, metrics, bce_weight=0.5, unlabelled=False):\n",
        "    bce = F.binary_cross_entropy_with_logits(pred, target.to(torch.float32))\n",
        "    pred = F.sigmoid(pred)\n",
        "    dice = dice_loss(pred, target)\n",
        "\n",
        "    target_np=target.data.cpu().numpy()\n",
        "    pred_np=pred.data.cpu().numpy()\n",
        "    MIoU= np.mean(sklearn.metrics.jaccard_score(np.argmax(target_np,axis=1).flatten(), np.argmax(pred_np,axis=1).flatten(), average=None))\n",
        "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
        "    if not unlabelled:\n",
        "      metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
        "      metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
        "      metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
        "      metrics['MIoU'] += MIoU * target.size(0)\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "gcyEresgpUZw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_metrics(metrics, epoch_samples, phase):\n",
        "    outputs = []\n",
        "    for k in metrics.keys():\n",
        "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
        "    print(\"{}: {}\".format(phase, \", \".join(outputs)))"
      ],
      "metadata": {
        "id": "C79o4w-4pWYT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = SegDataset(x_train,  train_transform1, train_transform2, img_dim=IMG_DIM)\n",
        "testing_set = SegDataset(x_test, train_transform1,train_transform2, img_dim=IMG_DIM)\n",
        "image_datasets = {'train': training_set, 'valid': testing_set}\n",
        "\n",
        "u_dir = \"/content/new/Train/Unlabeled/image\"\n",
        "unlabelled_paths = [os.path.join(u_dir, file) for file in os.listdir(u_dir)]\n",
        "unlabelled_set = SegDataset(unlabelled_paths[0:-500], trans1=train_transform1,trans2=train_transform2, img_dim=IMG_DIM, unlabelled=True)\n",
        "image_datasets[\"unlabelled\"] = unlabelled_set"
      ],
      "metadata": {
        "id": "lW4M1OrkpYKm"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the pretrained DeepLabV3 model\n",
        "model = models.segmentation.deeplabv3_resnet101(pretrained=True)\n",
        "model.classifier[4] = nn.Conv2d(256, len(CLASSES), kernel_size=(1, 1), stride=(1, 1))  # Adjust the output channels to the number of classes\n",
        "model.to(device)\n",
        "\n",
        "# Setup optimizer and learning rate scheduler\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR[0])\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "id": "MOiQf3tnp4n4"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, image_datasets, optimizer, scheduler, num_epochs=EPOCHS):\n",
        "    best_model_wts = model.state_dict()\n",
        "    best_miou = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch}/{num_epochs - 1}\")\n",
        "        print(\"-\" * 10)\n",
        "\n",
        "\n",
        "        for phase in ['train', 'valid', 'unlabelled']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            metrics = {'bce': 0.0, 'dice': 0.0, 'loss': 0.0, 'MIoU': 0.0}\n",
        "            epoch_samples = 0\n",
        "            for inputs, labels in tqdm(DataLoader(image_datasets[phase], batch_size=BATCH_SIZE[0], shuffle=True, num_workers=4)):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)['out']\n",
        "                    loss = calc_loss(outputs, labels, metrics)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                epoch_samples += inputs.size(0)\n",
        "\n",
        "            print_metrics(metrics, epoch_samples, phase)\n",
        "\n",
        "            if phase == 'valid' or phase == 'unlabelled':\n",
        "                miou = metrics['MIoU'] / epoch_samples\n",
        "                if miou > best_miou:\n",
        "                    best_miou = miou\n",
        "                    best_model_wts = model.state_dict()\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "        print()\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "5Nu5pHcCqANN"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(model, image_datasets, optimizer, scheduler, num_epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiDUtuWJqOLL",
        "outputId": "7ac06e7a-9f68-464e-b497-35908008ca93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/99\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/35 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g6oD4jmUqPrT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}